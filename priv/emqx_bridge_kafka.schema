%% emqx_bridge_kafka config
{mapping, "bridge.kafka.servers", "emqx_bridge_kafka.servers", [
  {default, {"127.0.0.1", "9092"}},
  {datatype, [integer, ip, string]}
]}.

{mapping, "bridge.kafka.connection_strategy", "emqx_bridge_kafka.connection_strategy", [
  {default, per_partition},
  {datatype, {enum, [per_partition, per_broker]}}
]}.

{mapping, "bridge.kafka.min_metadata_refresh_interval", "emqx_bridge_kafka.min_metadata_refresh_interval", [
  {datatype, {duration, ms}}
]}.

{mapping, "bridge.kafka.produce", "emqx_bridge_kafka.produce", [
  {default, sync},
  {datatype, {enum, [sync, async]}}
]}.

{mapping, "bridge.kafka.encode_payload_type", "emqx_bridge_kafka.encode_payload_type", [
  {default, base64},
  {datatype, {enum, [base64, plain]}}
]}.

{mapping, "bridge.kafka.produce.sync_timeout", "emqx_bridge_kafka.produce_sync_timeout", [
  {datatype, {duration, ms}}
]}.

{mapping, "bridge.kafka.replayq_dir", "emqx_bridge_kafka.replayq_dir", [
  {datatype, string}
]}.

{translation, "emqx_bridge_kafka.servers", fun(Conf) ->
  case cuttlefish:conf_get("bridge.kafka.servers", Conf) of
    {Ip, Port} -> [{Ip, Port}];
    S          ->
      ServerList = string:tokens(S, ","),
      lists:map(fun(Server) ->
        case string:tokens(Server, ":") of
          [Domain]          -> {Domain, 9092};
          [Domain, Port]    -> {Domain, list_to_integer(Port)}
        end
      end, ServerList)
  end
end}.

{mapping, "bridge.kafka.producer.replayq_seg_bytes", "emqx_bridge_kafka.producer", [
  {datatype, bytesize}
]}.

{mapping, "bridge.kafka.producer.required_acks", "emqx_bridge_kafka.producer", [
  {datatype, atom}
]}.

{mapping, "bridge.kafka.producer.ack_timeout", "emqx_bridge_kafka.producer", [
  {datatype, {duration, ms}}
]}.

{mapping, "bridge.kafka.producer.max_batch_bytes", "emqx_bridge_kafka.producer", [
  {datatype, bytesize}
]}.

{mapping, "bridge.kafka.producer.min_batch_bytes", "emqx_bridge_kafka.producer", [
  {datatype, bytesize}
]}.

{mapping, "bridge.kafka.producer.max_send_ahead", "emqx_bridge_kafka.producer", [
  {datatype, integer}
]}.

{mapping, "bridge.kafka.producer.compression", "emqx_bridge_kafka.producer", [
  {datatype, atom}
]}.

{translation, "emqx_bridge_kafka.producer", fun(Conf) ->
  Filter = fun(Opts) -> [{K, V} || {K, V} <- Opts, V =/= undefined] end,
  Filter([{replayq_seg_bytes, cuttlefish:conf_get("bridge.kafka.producer.replayq_seg_bytes", Conf, undefined)},
          {required_acks,     cuttlefish:conf_get("bridge.kafka.producer.required_acks", Conf, undefined)},
          {ack_timeout,       cuttlefish:conf_get("bridge.kafka.producer.ack_timeout", Conf, undefined)},
          {max_batch_bytes,   cuttlefish:conf_get("bridge.kafka.producer.max_batch_bytes", Conf, undefined)},
          {min_batch_bytes,   cuttlefish:conf_get("bridge.kafka.producer.min_batch_bytes", Conf, undefined)},
          {max_send_ahead,    cuttlefish:conf_get("bridge.kafka.producer.max_send_ahead", Conf, undefined)},
          {compression,       cuttlefish:conf_get("bridge.kafka.producer.compression", Conf, undefined)}])
end}.

{mapping, "bridge.kafka.hook.client.connected.$name", "emqx_bridge_kafka.hooks", [
  {datatype, string}
]}.

{mapping, "bridge.kafka.hook.client.disconnected.$name", "emqx_bridge_kafka.hooks", [
  {datatype, string}
]}.

{mapping, "bridge.kafka.hook.session.subscribed.$name", "emqx_bridge_kafka.hooks", [
  {datatype, string}
]}.

{mapping, "bridge.kafka.hook.session.unsubscribed.$name", "emqx_bridge_kafka.hooks", [
  {datatype, string}
]}.

{mapping, "bridge.kafka.hook.message.publish.$name", "emqx_bridge_kafka.hooks", [
  {datatype, string}
]}.

{mapping, "bridge.kafka.hook.message.acked.$name", "emqx_bridge_kafka.hooks", [
  {datatype, string}
]}.

{mapping, "bridge.kafka.hook.message.delivered.$name", "emqx_bridge_kafka.hooks", [
  {datatype, string}
]}.

{translation, "emqx_bridge_kafka.hooks", fun(Conf) ->
  Hooks = cuttlefish_variable:filter_by_prefix("bridge.kafka.hook", Conf),
  lists:map(fun({[_, _, _, Name1, Name2, _], Val}) ->
    {lists:concat([Name1, ".", Name2]), list_to_binary(Val)}
  end, Hooks)
end}.

{mapping, "bridge.kafka.sock.buffer", "emqx_bridge_kafka.sock_opts", [
  {datatype, bytesize}
]}.

{mapping, "bridge.kafka.sock.recbuf", "emqx_bridge_kafka.sock_opts", [
  {datatype, bytesize}
]}.

{mapping, "bridge.kafka.sock.sndbuf", "emqx_bridge_kafka.sock_opts", [
  {datatype, bytesize}
]}.

{mapping, "bridge.kafka.sock.read_packets", "emqx_bridge_kafka.sock_opts", [
  {datatype, integer}
]}.

{translation, "emqx_bridge_kafka.sock_opts", fun(Conf) ->
  Filter = fun(Opts) -> [{K, V} || {K, V} <- Opts, V =/= undefined] end,
  Filter([{buffer,       cuttlefish:conf_get("bridge.kafka.sock.buffer", Conf, undefined)},
          {recbuf,       cuttlefish:conf_get("bridge.kafka.sock.recbuf", Conf, undefined)},
          {sndbuf,       cuttlefish:conf_get("bridge.kafka.sock.sndbuf", Conf, undefined)},
          {read_packets, cuttlefish:conf_get("bridge.kafka.sock.read_packets", Conf, undefined)}])
end}.


{mapping, "bridge.kafka.consumer.config.min_bytes", "emqx_bridge_kafka.consumer_config", [
    {default, 0},
    {datatype, integer}
]}.

{mapping, "bridge.kafka.consumer.config.max_bytes", "emqx_bridge_kafka.consumer_config", [
    {datatype, bytesize}
]}.

{mapping, "bridge.kafka.consumer.config.max_wait_time", "emqx_bridge_kafka.consumer_config", [
    {datatype, {duration, ms}}
]}.

{mapping, "bridge.kafka.consumer.config.sleep_timeout", "emqx_bridge_kafka.consumer_config", [
    {datatype, {duration, ms}}
]}.

{mapping, "bridge.kafka.consumer.config.prefetch_count", "emqx_bridge_kafka.consumer_config", [
    {default, 10},
    {datatype, integer}
]}.

{mapping, "bridge.kafka.consumer.config.prefetch_bytes", "emqx_bridge_kafka.consumer_config", [
    {datatype, bytesize}
]}.

{mapping, "bridge.kafka.consumer.config.begin_offset", "emqx_bridge_kafka.consumer_config", [
    {default, earliest},
    {datatype, {enum, [earliest, earliest]}}
]}.

{mapping, "bridge.kafka.consumer.config.offset_reset_policy", "emqx_bridge_kafka.consumer_config", [
    {default, reset_by_subscriber},
    {datatype, {enum, [reset_by_subscriber, reset_to_earliest, reset_to_latest]}}
]}.

{mapping, "bridge.kafka.consumer.config.size_stat_window", "emqx_bridge_kafka.consumer_config", [
    {datatype, integer}
]}.

{translation, "emqx_bridge_kafka.consumer_config", fun(Conf) ->
  Filter = fun(Opts) -> [{K, V} || {K, V} <- Opts, V =/= undefined] end,
  Filter([{min_bytes,       cuttlefish:conf_get("bridge.kafka.consumer.config.min_bytes", Conf, undefined)},
          {max_bytes,       cuttlefish:conf_get("bridge.kafka.consumer.config.max_bytes", Conf, undefined)},
          {max_wait_time,       cuttlefish:conf_get("bridge.kafka.consumer.config.max_wait_time", Conf, undefined)},
          {sleep_timeout, cuttlefish:conf_get("bridge.kafka.consumer.config.sleep_timeout", Conf, undefined)},
          {prefetch_count, cuttlefish:conf_get("bridge.kafka.consumer.config.prefetch_count", Conf, undefined)},
          {prefetch_bytes, cuttlefish:conf_get("bridge.kafka.consumer.config.prefetch_bytes", Conf, undefined)},
          {begin_offset, cuttlefish:conf_get("bridge.kafka.consumer.config.begin_offset", Conf, undefined)},
          {offset_reset_policy, cuttlefish:conf_get("bridge.kafka.consumer.config.offset_reset_policy", Conf, undefined)},
          {size_stat_window, cuttlefish:conf_get("bridge.kafka.consumer.config.size_stat_window", Conf, undefined)}])
end}.


{mapping, "bridge.kafka.consumer.coordinator.partition_assignment_strategy", "emqx_bridge_kafka.coordinator", [
    {default, roundrobin_v2},
    {datatype, {enum, [roundrobin_v2, callback_implemented]}}
]}.

{mapping, "bridge.kafka.consumer.coordinator.session_timeout_seconds", "emqx_bridge_kafka.coordinator", [
    {default, 10},
    {datatype, integer}
]}.

{mapping, "bridge.kafka.consumer.coordinator.heartbeat_rate_seconds", "emqx_bridge_kafka.coordinator", [
    {default, 2},
    {datatype, integer}
]}.

{mapping, "bridge.kafka.consumer.coordinator.max_rejoin_attempts", "emqx_bridge_kafka.coordinator", [
    {default, 5},
    {datatype, integer}
]}.

{mapping, "bridge.kafka.consumer.coordinator.rejoin_delay_seconds", "emqx_bridge_kafka.coordinator", [
    {default, 1},
    {datatype, integer}
]}.

{mapping, "bridge.kafka.consumer.coordinator.offset_commit_policy", "emqx_bridge_kafka.coordinator", [
    {default, commit_to_kafka_v2},
    {datatype, {enum, [commit_to_kafka_v2, consumer_managed]}}
]}.

{mapping, "bridge.kafka.consumer.coordinator.offset_commit_interval_seconds", "emqx_bridge_kafka.coordinator", [
    {default, 5},
    {datatype, integer}
]}.

{mapping, "bridge.kafka.consumer.coordinator.offset_retention_seconds", "emqx_bridge_kafka.coordinator", [
    {default, -1},
    {datatype, integer}
]}.

{mapping, "bridge.kafka.consumer.coordinator.protocol_name", "emqx_bridge_kafka.coordinator", [
  {datatype, string}
]}.

{translation, "emqx_bridge_kafka.coordinator", fun(Conf) ->
  Filter = fun(Opts) -> [{K, V} || {K, V} <- Opts, V =/= undefined] end,
  Filter([{partition_assignment_strategy,       cuttlefish:conf_get("bridge.kafka.consumer.coordinator.partition_assignment_strategy", Conf, undefined)},
          {session_timeout_seconds,       cuttlefish:conf_get("bridge.kafka.consumer.coordinator.session_timeout_seconds", Conf, undefined)},
          {heartbeat_rate_seconds,       cuttlefish:conf_get("bridge.kafka.consumer.coordinator.heartbeat_rate_seconds", Conf, undefined)},
          {max_rejoin_attempts, cuttlefish:conf_get("bridge.kafka.consumer.coordinator.max_rejoin_attempts", Conf, undefined)},
          {rejoin_delay_seconds, cuttlefish:conf_get("bridge.kafka.consumer.coordinator.rejoin_delay_seconds", Conf, undefined)},
          {offset_commit_policy, cuttlefish:conf_get("bridge.kafka.consumer.coordinator.offset_commit_policy", Conf, undefined)},
          {offset_commit_interval_seconds, cuttlefish:conf_get("bridge.kafka.consumer.coordinator.offset_commit_interval_seconds", Conf, undefined)},
          {offset_retention_seconds, cuttlefish:conf_get("bridge.kafka.consumer.coordinator.offset_retention_seconds", Conf, undefined)},
          {protocol_name, cuttlefish:conf_get("bridge.kafka.consumer.coordinator.protocol_name", Conf, undefined)}])
end}.


{mapping, "bridge.kafka.consumer.messages.device_cmd", "emqx_bridge_kafka.messages", [
    {datatype, string}
]}.

{translation, "emqx_bridge_kafka.messages", fun(Conf) ->
  Messages = cuttlefish_variable:filter_by_prefix("bridge.kafka.consumer.messages", Conf),
  lists:map(fun({[_, _, _, _,Name], Val}) ->
    {Name, list_to_binary(Val)}
  end, Messages)
end}.