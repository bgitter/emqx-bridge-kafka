##====================================================================
## Configuration for EMQ X Kafka Bridge
##====================================================================

## Cluster support
## bridge.kafka.servers = 127.0.0.1:9092,127.0.0.2:9092,127.0.0.3:9092
bridge.kafka.servers = 127.0.0.1:9092

## default per_partition, can also be per_broker.
## This is to configure how client manages connections:
## one connection per-partition or one connection per-broker.
## per_partition may give better throughput, but it could be
## quite exhausting for both beam and kafka cluster when
## there is a great number of partitions
bridge.kafka.connection_strategy = per_partition

## This is to avoid excessive metadata refresh and partition
## leader reconnect when a lot of connections restart around the same moment.
## Also, when kafka partition leader broker is down,
## it usually takes a few seconds to get a new leader elacted,
## hence it is a good idea to have a delay before trying to reconnect.
bridge.kafka.min_metadata_refresh_interval = 5S

## Pick a partition producer and sync/async.
bridge.kafka.produce = sync

bridge.kafka.produce.sync_timeout = 3s

## Base directory for replayq to store messages on disk.
## If this config entry if missing or set to undefined,
## replayq works in a mem-only manner.
## i.e. messages are not queued on disk -- in such case,
## the send or send_sync API callers are responsible for
## possible message loss in case of application,
## network or kafka disturbances. For instance,
## in the wolff:send API caller may trap_exit then
## react on parition-producer worker pid's 'EXIT'
## message to issue a retry after restarting the producer.
## bridge.kafka.replayq_dir = /tmp/emqx_bridge_kafka/

## default=10MB, replayq segment size.
## bridge.kafka.producer.replayq_seg_bytes = 10MB

## all_isr, leader_only or none, see kafka_protocol lib doc.
##bridge.kafka.producer.required_acks = none

## default=10000. Timeout leader wait for replicas before reply to producer.
##bridge.kafka.producer.ack_timeout = 10S

## default number of message sets sent on wire before block waiting for acks
##bridge.kafka.producer.max_batch_bytes = 1024KB

## by default, send max 1 MB of data in one batch (message set)
##bridge.kafka.producer.min_batch_bytes = 0

## Number of batches to be sent ahead without receiving ack for the last request.
## Must be 0 if messages must be delivered in strict order.
##bridge.kafka.producer.max_send_ahead = 0

## by default, no compression
##bridge.kafka.producer.compression = no_compression

## bridge.kafka.encode_payload_type = base64

## bridge.kafka.sock.buffer = 32KB
## bridge.kafka.sock.recbuf = 32KB
bridge.kafka.sock.sndbuf = 1MB
## bridge.kafka.sock.read_packets = 20

## Bridge Kafka Hooks
## ${topic}: the kafka topics to which the messages will be published.
## ${filter}: the mqtt topic (may contain wildcard) on which the action will be performed .
bridge.kafka.hook.client.connected.1     = {"topic":"emqx.bridge.topic.input"}
## bridge.kafka.hook.client.disconnected.1  = {"topic":"emqx.bridge.topic"}
## bridge.kafka.hook.session.subscribed.1   = {"filter":"#", "topic":"emqx.bridge.topic"}
## bridge.kafka.hook.session.unsubscribed.1 = {"filter":"#", "topic":"emqx.bridge.topic"}
## bridge.kafka.hook.message.publish.1      = {"filter":"#", "topic":"emqx.bridge.topic"}
## bridge.kafka.hook.message.delivered.1    = {"filter":"#", "topic":"emqx.bridge.topic"}
## bridge.kafka.hook.message.acked.1        = {"filter":"#", "topic":"emqx.bridge.topic"}

## More Configures
## partitioner strategy:
## Option:  random | roundrobin | first_key_dispatch
## Example: bridge.kafka.hook.message.publish.1 = {"filter":"#", "topic":"MessagePublish", "strategy":"random"}

## key:
## Option: ${clientid} | ${username}
## Example: bridge.kafka.hook.message.publish.1 = {"filter":"#", "topic":"MessagePublish", "key":"${clientid}"}

## format:
## Option: json | json
## Example: bridge.kafka.hook.message.publish.1 = {"filter":"#", "topic":"MessagePublish", "format":"json"}

## kafka consumer config
## Minimal bytes to fetch in a batch of messages (optional, default = 0)
bridge.kafka.consumer.config.min_bytes = 0
# Maximum bytes to fetch in a batch of messages (optional, default = 1MB)
# NOTE: this value might be expanded to retry when it is not enough
# to fetch even a single message, then slowly shrinked back to the given value.
bridge.kafka.consumer.config.max_bytes=1MB
# Max number of seconds allowed for the broker to collect `min_bytes' of
# messages in fetch response (optional, default = 10S)
bridge.kafka.consumer.config.max_wait_time=10S
# Allow consumer process to sleep this amount of seconds if kafka replied
# 'empty' message set (optional, default = 1S)
bridge.kafka.consumer.config.sleep_timeout=1S
# The window size (number of messages) allowed to fetch-ahead (optional, default = 10)
bridge.kafka.consumer.config.prefetch_count=10
# The total number of bytes allowed to fetch-ahead.
# wolff_consumer is greed, it only stops fetching more messages in
# when number of unacked messages has exceeded prefetch_count AND
# the unacked total volume has exceeded prefetch_bytes (optional, default = 100KB)
bridge.kafka.consumer.config.prefetch_bytes=100KB
# The offset from which to begin fetch requests
# (optional, default = earliest)  latest | earliest
bridge.kafka.consumer.config.begin_offset=earliest
# How to reset `begin_offset' if `OffsetOutOfRange' exception is received.
# `reset_by_subscriber': consumer is suspended
#           (`is_suspended=true' in state) and wait for subscriber to re-subscribe with a new
#           `begin_offset' option.
# `reset_to_earliest': consume from the earliest offset.
# `reset_to_latest': consume from the last available offset
# (optional, default = reset_by_subscriber)
bridge.kafka.consumer.config.offset_reset_policy=reset_by_subscriber
# The moving-average window size to calculate average message
# size.  Average message size is used to shrink `max_bytes' in
# fetch requests after it has been expanded to fetch a large
# message. Use 0 to immediately shrink back to original
# `max_bytes' from config.  A size estimation allows users to set
# a relatively small `max_bytes', then let it dynamically adjust
# to a number around `PrefetchCount * AverageSize'
# (optional, default = 5)
bridge.kafka.consumer.config.size_stat_window=5

# kafka consumer coordinator config
# Possible values:
#  roundrobin_v2 (topic-sticky) => Take all topic-offset (sorted `topic_partition()' list),
#       assign one to each member in a roundrobin fashion. Only partitions
#       in the subscription topic list are assigned
#  callback_implemented => Call `CbModule:assign_partitions/2' to assign partitions
# (optional, default = `roundrobin_v2')
bridge.kafka.consumer.coordinator.partition_assignment_strategy = roundrobin_v2
# Time in seconds for the group coordinator broker to consider a member
# 'down' if no heartbeat or any kind of requests received from a broker
# in the past N seconds.
# A group member may also consider the coordinator broker 'down' if no
# heartbeat response received in the past N seconds
# (optional, default = 10)
bridge.kafka.consumer.coordinator.session_timeout_seconds = 10
# Time in seconds for the member to 'ping' the group coordinator.
# OBS: Care should be taken when picking the number, on one hand, we do
#       not want to flush the broker with requests if we set it too low,
#       on the other hand, if set it too high, it may take too long for
#       the members to realise status changes of the group such as
#       assignment re-balance or group coordinator switchover etc
# (optional, default = 2)
bridge.kafka.consumer.coordinator.heartbeat_rate_seconds = 2
# Maximum number of times allowed for a member to re-join the group.
# The gen_server will stop if it reached the maximum number of retries.
# OBS: 'let it crash' may not be the optimal strategy here because
#       the group member id is kept in the gen_server looping state and
#       it is reused when re-joining the group
# (optional, default = 5)
bridge.kafka.consumer.coordinator.max_rejoin_attempts = 5
# Delay in seconds before re-joining the group
# (optional, default = 1)
bridge.kafka.consumer.coordinator.rejoin_delay_seconds = 1
# How/where to commit offsets, possible values:
#   `commit_to_kafka_v2': Group coordinator will commit the
#       offsets to kafka using version 2 OffsetCommitRequest
#   `consumer_managed': The group member (e.g. wolff_group_subscriber.erl) is responsible for
#       persisting offsets to a local or centralized storage.
#       And the callback `get_committed_offsets' should be
#       implemented to allow group coordinator to retrieve the committed offsets
# (optional, default = `commit_to_kafka_v2')
bridge.kafka.consumer.coordinator.offset_commit_policy = commit_to_kafka_v2
# The time interval between two OffsetCommitRequest messages.
# This config is irrelevant if `offset_commit_policy' is `consumer_managed'
# (optional, default = 5)
bridge.kafka.consumer.coordinator.offset_commit_interval_seconds = 5
# How long the time is to be kept in kafka before it is deleted.
# The default special value -1 indicates that the __consumer_offsets topic retention policy is used.
# This config is irrelevant if `offset_commit_policy' is `consumer_managed'
# (optional, default = -1)
bridge.kafka.consumer.coordinator.offset_retention_seconds = -1
# This is the protocol name used when join a group, if not given,
# by default `partition_assignment_strategy' is used as the protocol name.
# Setting a protocol name allows to interact with consumer group members
# designed in other programing languages. For example, 'range' is the most
# commonly used protocol name for JAVA client. However, wolff only supports
# roundrobin protocol out of the box, in order to mimic 'range' protocol
# one will have to do it via `callback_implemented' assignment strategy
# (optional, default = roundrobin_v2)
bridge.kafka.consumer.coordinator.protocol_name = roundrobin_v2

# kafka consumer message from topic
bridge.kafka.consumer.messages.device_cmd = {"topic": "emqx.bridge.topic.output", "mountpoint": "${topic}", "groupId": "mqtt_bridge_kafka"}